{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is how a neural network learns to add, multiply and compare handwritten digits WITHOUT knowing their values "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p align=\"center\"> <img src=\"https://i.dlpng.com/static/png/6906777_preview.png\"> </p>   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I described in a [previous post](https://blog.jovian.ai/how-to-train-supervised-machine-learning-algorithms-without-labeled-data-6ebddc01a00f), how useful are autoencoders in  automated labeling. The main property of these networks is their ability to learn features/patterns in the data. This is in fact not specific to autoencoders and can be implemented using other unsupervised techniques, mainly **PCA**.  \r\n",
    "The ability to detect and learn features in data can be used in other areas.  \r\n",
    "\r\n",
    "In this post, I will present some applications of convolutional autoencoders:  \r\n",
    "- First, a convolutional autoencoder will be trained on **MNIST** data.\r\n",
    "- After the training of the encoder and decoder, we will freeze their weights and use them with additional dense layers to \"learn\" arithmetic operations, namely addition, multiplication and comparison.  \r\n",
    "The trick is to *never* explicitly associate the handwritten digits in **MNIST** dataset with their respective labels. We will see that the neural networks will be nevertheless able to reach 97+% accuracy in all cases on unseen data.\r\n",
    "\r\n",
    "The first step is described in the following diagram:\r\n",
    "<p align=\"center\"> <img src=\"https://i.imgur.com/chLUEdp.png\"> </p>   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the second step, we will use the encoder in series with dense layers to perform arithmetic operations: addition, multiplication and comparison. We will train only the dense layer weights, and supply the results of the operations as labels. note that we will not supply the digits values (labels).\r\n",
    "\r\n",
    "<p align=\"center\"> <img src=\"https://i.imgur.com/s8U8up4.png\"> </p> \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training an autoencoder on MNIST data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similar to the previous article, we will use MNIST data in this experiment. The autoencoder will learn the handwritten digits features using 60000 training samples. We import MNIST using *KERAS* library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import libraries and setup \r\n",
    "import keras\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import logging\r\n",
    "logging.getLogger('tensorflow').disabled = True\r\n",
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, UpSampling2D, Reshape, Concatenate, Input\r\n",
    "from keras.callbacks import EarlyStopping\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10, restore_best_weights=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import mnist\r\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
    "print(x_train.shape,y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We scale the data in the range `[0,1]` and reshape it to *KERAS* format for pictures (nbr_samples x width x height x channels) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#normalize data\r\n",
    "if x_train.max() >1:\r\n",
    "    x_train = x_train / 255\r\n",
    "    x_test = x_test / 255\r\n",
    "\r\n",
    "default_shape = x_train.shape\r\n",
    "#reshape input data to 1 channel\r\n",
    "x_train = x_train.reshape(-1,default_shape[1],default_shape[2],1)\r\n",
    "x_test = x_test.reshape(-1,default_shape[1],default_shape[2],1)\r\n",
    "image_dim = x_train.shape[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will implement a similar autoencoder architecture as in [[1]](https://blog.jovian.ai/how-to-train-supervised-machine-learning-algorithms-without-labeled-data-6ebddc01a00f). It is based on a series of convolutional layers, that will gradually encode the 28x28 image (784 pixel) into a 100 elements array, and decode that representation back to the original format. The resulting image -after the training step- will hopefully resemble to the original one."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create an autoencoder / decoder \r\n",
    "encoder = Sequential()\r\n",
    "encoder.add(Conv2D(32,kernel_size=(3,3), strides=(1,1),padding='same', activation='selu',input_shape=image_dim))\r\n",
    "encoder.add(MaxPooling2D(2,2))\r\n",
    "encoder.add(Conv2D(64,kernel_size=(3,3), strides=(1,1),padding='same',activation='selu'))\r\n",
    "encoder.add(MaxPooling2D(2,2))\r\n",
    "encoder.add(Conv2D(128,kernel_size=(3,3), strides=(1,1),padding='same',activation='selu'))\r\n",
    "encoder.add(Flatten())\r\n",
    "encoder.add(Dense(100,activation='sigmoid'))\r\n",
    "encoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder_out_dim = encoder.layers[-1].output_shape[1:] # dimension of the encoder output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "decoder = Sequential()\r\n",
    "decoder.add(Dense(6272, activation='sigmoid', input_shape=encoder_out_dim))\r\n",
    "decoder.add(Reshape(( 7, 7, 128)))\r\n",
    "decoder.add(Conv2D(128,kernel_size=(3,3), strides=(1,1),padding='same', activation='selu'))\r\n",
    "decoder.add(UpSampling2D((2,2)))\r\n",
    "decoder.add(Conv2D(64,kernel_size=(3,3), strides=(1,1),padding='same', activation='selu'))\r\n",
    "decoder.add(UpSampling2D((2,2)))\r\n",
    "decoder.add(Conv2D(1,kernel_size=(3,3), strides=(1,1),padding='same', activation='sigmoid'))\r\n",
    "\r\n",
    "decoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The autoencoder is created using the encoder and the decoder:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "enc_dec = Sequential([encoder,decoder])\r\n",
    "enc_dec.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It will be trained as a set of binary classifiers for each pixel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "enc_dec.compile(optimizer='nadam', loss = 'binary_crossentropy')\r\n",
    "history = enc_dec.fit(x_train,x_train, batch_size=1000,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es,es])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The early stopping will make sure the autoencoder will not overfit the training data. There are two ways to verify the network. First, we can evaluate the loss function on test data, and expect it to be close to the loss value on the training data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "enc_dec.evaluate(x_test,x_test,batch_size=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "enc_dec.evaluate(x_train,x_train,batch_size=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is very close, around `0.08` for both data sets. The second method is to check the resulting reconstitution that we obtain for a random sample from the test data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_label = np.random.randint(0,9999)\r\n",
    "img_sample = x_test[random_label,:,:].reshape((1,28,28,1))\r\n",
    "plt.imshow(img_sample.reshape(28,28), cmap='gray');\r\n",
    "pred_img = enc_dec.predict(img_sample) \r\n",
    "plt.figure();\r\n",
    "plt.imshow(pred_img.reshape(28,28), cmap='gray');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*A picture is worth a thousand words!* Just to be on the safe side, I ran this test multiple times and the results were consistent. Let's save the encoder and the decoder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save models\r\n",
    "encoder.save('encoder')\r\n",
    "decoder.save('decoder')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a trained encoder and decoder, let's focus on the *encoder*. For each image, is associated a representation that captures most of the interesting features. This representation is sufficient to reconstitute the image using the decoder. Here is the representation of the sample image we used earlier: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "representation_sample = encoder.predict(img_sample)\r\n",
    "print(representation_sample) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using these 100 numbers, we generate a 28x28 image (784 pixels)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "recons_image = decoder.predict(representation_sample)\r\n",
    "plt.imshow(recons_image.reshape(28,28), cmap='gray');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here is where the *fun part* begins! using the lower-dimension representation, let's do some math."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning how to add two handwritten digits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The idea is simple. Using the representation of two images, we train a neural network to compute their sum. We will not provide the value of each digit, but we will provide the sum during the training step.  \r\n",
    "We will be performing addition between numbers in the range [0-9]. The results will be in the range [0-18]. So the results will be coded using two outputs:  \r\n",
    "1- Units, multiclass output [0,1,2,3,4,5,6,7,8,9]  \r\n",
    "2- Tens, binary output [0,1]  \r\n",
    "\r\n",
    "<p align=\"center\"> <img src=\"https://i.imgur.com/Zgnd82F.png\"> </p> \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the functional API in *KERAS* we define the network architecture. First, we import the encoder *twice* and freeze its weights:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# duplicate encoders and freeze weights\r\n",
    "encoder1 = keras.models.load_model('encoder') \r\n",
    "encoder1._name = 'encoder1'\r\n",
    "encoder1.trainable = False\r\n",
    "\r\n",
    "encoder2 = keras.models.load_model('encoder')\r\n",
    "encoder2._name = 'encoder2'\r\n",
    "encoder2.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the encoders, we build the 'addition' model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create model to learn addition\r\n",
    "input1 = Input(shape=image_dim)\r\n",
    "input2 = Input(shape=image_dim)\r\n",
    "enc1_out = encoder1(input1)\r\n",
    "enc2_out = encoder2(input2)\r\n",
    "model_c = Concatenate()([enc1_out,enc2_out])\r\n",
    "model_c = Dense(1000,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_b1 = Dense(200,activation='relu')(model_c)\r\n",
    "model_b2 = Dense(200,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_b1 = Dense(100,activation='relu')(model_b1)\r\n",
    "model_b2 = Dense(100,activation='relu')(model_b2)\r\n",
    "\r\n",
    "units =  Dense(10,activation='softmax',name ='units')(model_b1)\r\n",
    "tens = Dense(1,activation='sigmoid',name ='tens')(model_b2)\r\n",
    "\r\n",
    "model_addition = Model(inputs=[input1,input2],outputs=[units,tens])\r\n",
    "\r\n",
    "model_addition.compile(optimizer='nadam', loss = ['categorical_crossentropy','binary_crossentropy'], metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This model has two inputs (the two handwritten digits images) and two outputs (units and tens of the sum). We will use two different losses due to the nature of the outputs. Note that there is a common hidden layer of 1000 units, and then two branches (one for each output).  \r\n",
    "We need to create datasets to train and test our model. Inputs will be random combinations of handwritten digits. Outputs will be the sums for each combination. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate a dataset for additions\r\n",
    "train_size = 200000\r\n",
    "random_labels1 = np.random.randint(0,25000,train_size)\r\n",
    "random_labels2 = np.random.randint(0,25000,train_size)\r\n",
    "\r\n",
    "x_train_1 = x_train[random_labels1]\r\n",
    "x_train_2 = x_train[random_labels2]\r\n",
    "\r\n",
    "y_train_1 = y_train[random_labels1]\r\n",
    "y_train_2 = y_train[random_labels2]\r\n",
    "\r\n",
    "y_add = y_train_1 + y_train_2\r\n",
    "y_add_tens = y_add //10 \r\n",
    "y_add_units = y_add %10 \r\n",
    "y_add_units_cat = to_categorical(y_add_units)\r\n",
    "\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "test_size = 5000\r\n",
    "random_labels1 = np.random.randint(0,10000,test_size)\r\n",
    "random_labels2 = np.random.randint(0,10000,test_size)\r\n",
    "\r\n",
    "x_test_1 = x_test[random_labels1]\r\n",
    "x_test_2 = x_test[random_labels2]\r\n",
    "\r\n",
    "y_test_1 = y_test[random_labels1]\r\n",
    "y_test_2 = y_test[random_labels2]\r\n",
    "\r\n",
    "y_test_add = y_test_1 + y_test_2\r\n",
    "y_test_add_tens = y_test_add //10 \r\n",
    "y_test_add_units = y_test_add %10 \r\n",
    "y_test_add_units_cat = to_categorical(y_test_add_units)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are ready to train our model! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_addition = model_addition.fit([x_train_1,x_train_2],[y_add_units_cat,y_add_tens], batch_size=100,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es,es])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the end of the training, the accuracy on both outputs is pretty good (98% and 99,5%). Let's see first how the model performs on the test data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_results = model_addition.evaluate([x_test_1,x_test_2],[y_test_add_units_cat,y_test_add_tens],batch_size=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results are still in the 9x%. We can show a random sample of the model predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_label_1 = np.random.randint(0,9999)\r\n",
    "random_label_2 = np.random.randint(0,9999)\r\n",
    "\r\n",
    "img_sample1 = x_test[random_label_1,:,:].reshape((1,28,28,1))\r\n",
    "img_sample2 = x_test[random_label_2,:,:].reshape((1,28,28,1))\r\n",
    "\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.imshow(img_sample1.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.imshow(img_sample2.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "prediction = model_addition.predict([img_sample1,img_sample2])\r\n",
    "unit = prediction[0]\r\n",
    "ten = prediction[1]\r\n",
    "\r\n",
    "sum_images = np.argmax(unit)+10*np.round(ten)\r\n",
    "print('sum =',sum_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results look promising! We actually could improve the accuracy by training the model on more random samples (increase `train_size` value) or tweak the model architecture. One last thing: save the model!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the model\r\n",
    "model_addition.save('model_addition')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning how to multiply two handwritten digits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a similar method, we can train a neural network to compute multiplication result of two handwritten digits. The main difference is that the output will be in the range [0,81]. The network will output two values:  \r\n",
    "1- units, multiclass [0,1,2,3,4,5,6,7,8,9]  \r\n",
    "2- tens, multiclass [0,1,2,3,4,5,6,7,8] \r\n",
    "\r\n",
    "We will use the same architecture as previously, with a slight modification in the output layer (softmax instead of sigmoid, and 8 neurons instead of 1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# duplicate encoders and freeze weights\r\n",
    "encoder3 = keras.models.load_model('encoder') \r\n",
    "encoder3._name = 'encoder1'\r\n",
    "encoder3.trainable = False\r\n",
    "\r\n",
    "encoder4 = keras.models.load_model('encoder')\r\n",
    "encoder4._name = 'encoder2'\r\n",
    "encoder4.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create model to learn multiplication\r\n",
    "input1 = Input(shape=image_dim)\r\n",
    "input2 = Input(shape=image_dim)\r\n",
    "enc1_out = encoder3(input1)\r\n",
    "enc2_out = encoder4(input2)\r\n",
    "model_c = Concatenate()([enc1_out,enc2_out])\r\n",
    "model_c = Dense(1000,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_b1 = Dense(200,activation='relu')(model_c)\r\n",
    "model_b2 = Dense(200,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_b1 = Dense(100,activation='relu')(model_b1)\r\n",
    "model_b2 = Dense(100,activation='relu')(model_b2)\r\n",
    "\r\n",
    "units =  Dense(10,activation='softmax',name ='units')(model_b1)\r\n",
    "tens = Dense(9,activation='softmax',name ='tens')(model_b2)\r\n",
    "\r\n",
    "model_mult = Model(inputs=[input1,input2],outputs=[units,tens])\r\n",
    "\r\n",
    "model_mult.compile(optimizer='nadam', loss = ['categorical_crossentropy','categorical_crossentropy'], metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to create data for training and testing as we did previously. We already generated random images, so all we need now is to create labels by multiplying the values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate a dataset for multiplication\r\n",
    "\r\n",
    "y_mult = y_train_1 * y_train_2\r\n",
    "y_mult_tens = y_mult //10 \r\n",
    "y_mult_units = y_mult %10 \r\n",
    "y_mult_units_cat = to_categorical(y_mult_units)\r\n",
    "y_mult_tens_cat = to_categorical(y_mult_tens)\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "\r\n",
    "y_test_mult = y_test_1 * y_test_2\r\n",
    "y_test_mult_tens = y_test_mult //10 \r\n",
    "y_test_mult_units = y_test_mult %10 \r\n",
    "y_test_mult_units_cat = to_categorical(y_test_mult_units)\r\n",
    "y_test_mult_tens_cat = to_categorical(y_test_mult_tens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next step is to train the model, and test it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_mult = model_mult.fit([x_train_1,x_train_2],[y_mult_units_cat,y_mult_tens_cat], batch_size=100,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es,es])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_results = model_mult.evaluate([x_test_1,x_test_2],[y_test_mult_units_cat,y_test_mult_tens_cat],batch_size=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We achieve similar performances (slightly better actually!) when compared to addition. Let's see how the model works on sample data: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_label_1 = np.random.randint(0,9999)\r\n",
    "random_label_2 = np.random.randint(0,9999)\r\n",
    "\r\n",
    "img_sample1 = x_test[random_label_1,:,:].reshape((1,28,28,1))\r\n",
    "img_sample2 = x_test[random_label_2,:,:].reshape((1,28,28,1))\r\n",
    "\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.imshow(img_sample1.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.imshow(img_sample2.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "prediction = model_mult.predict([img_sample1,img_sample2])\r\n",
    "unit = prediction[0]\r\n",
    "ten = prediction[1]\r\n",
    "\r\n",
    "mult_images = np.argmax(unit)+10*np.argmax(ten)\r\n",
    "print('multiplication result =',mult_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the model\r\n",
    "model_mult.save('model_mult')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning how to compare two handwritten digits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last arithmetic operation our model will predict is the comparison. The model will have one binary output (1 if image1 > image2 and 0 elsewhere). We proceed the same way as previously."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# duplicate encoders and freeze weights\r\n",
    "encoder5 = keras.models.load_model('encoder') \r\n",
    "encoder5._name = 'encoder1'\r\n",
    "encoder5.trainable = False\r\n",
    "\r\n",
    "encoder6 = keras.models.load_model('encoder')\r\n",
    "encoder6._name = 'encoder2'\r\n",
    "encoder6.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create model to learn comparison\r\n",
    "input1 = Input(shape=image_dim)\r\n",
    "input2 = Input(shape=image_dim)\r\n",
    "enc1_out = encoder5(input1)\r\n",
    "enc2_out = encoder6(input2)\r\n",
    "model_c = Concatenate()([enc1_out,enc2_out])\r\n",
    "model_c = Dense(1000,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_c = Dense(200,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_c = Dense(100,activation='relu')(model_c)\r\n",
    "\r\n",
    "comp =  Dense(1,activation='sigmoid',name ='comp')(model_c)\r\n",
    "\r\n",
    "\r\n",
    "model_comp = Model(inputs=[input1,input2],outputs=[comp])\r\n",
    "\r\n",
    "model_comp.compile(optimizer='nadam', loss = ['binary_crossentropy'], metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate a dataset for comparison\r\n",
    "y_comp = y_train_1 > y_train_2\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "y_test_comp = y_test_1 > y_test_2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_comp = model_comp.fit([x_train_1,x_train_2],y_comp, batch_size=100,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_results = model_comp.evaluate([x_test_1,x_test_2],y_test_comp,batch_size=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_label_1 = np.random.randint(0,9999)\r\n",
    "random_label_2 = np.random.randint(0,9999)\r\n",
    "\r\n",
    "img_sample1 = x_test[random_label_1,:,:].reshape((1,28,28,1))\r\n",
    "img_sample2 = x_test[random_label_2,:,:].reshape((1,28,28,1))\r\n",
    "\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.imshow(img_sample1.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.imshow(img_sample2.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "prediction = np.round(model_comp.predict([img_sample1,img_sample2]))\r\n",
    "\r\n",
    "\r\n",
    "print('comparison result =',prediction,'1 if the number on the left is greater, 0 elsewhere')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the model\r\n",
    "model_comp.save('model_comp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion and future work"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}