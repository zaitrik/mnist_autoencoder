{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import libraries and setup \r\n",
    "import keras\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import logging\r\n",
    "logging.getLogger('tensorflow').disabled = True\r\n",
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, UpSampling2D, Reshape, Concatenate, Input\r\n",
    "from keras.callbacks import EarlyStopping\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10, restore_best_weights=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import mnist\r\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
    "print(x_train.shape,y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#normalize data\r\n",
    "if x_train.max() >1:\r\n",
    "    x_train = x_train / 255\r\n",
    "    x_test = x_test / 255\r\n",
    "\r\n",
    "default_shape = x_train.shape\r\n",
    "#reshape input data to 1 channel\r\n",
    "x_train = x_train.reshape(-1,default_shape[1],default_shape[2],1)\r\n",
    "x_test = x_test.reshape(-1,default_shape[1],default_shape[2],1)\r\n",
    "image_dim = x_train.shape[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# duplicate encoders and freeze weights\r\n",
    "encoder1 = keras.models.load_model('C:\\Mounir\\MyPython\\work\\mnist_autoencoder\\encoder') \r\n",
    "encoder1._name = 'encoder1'\r\n",
    "encoder1.trainable = False\r\n",
    "\r\n",
    "encoder2 = keras.models.load_model('C:\\Mounir\\MyPython\\work\\mnist_autoencoder\\encoder')\r\n",
    "encoder2._name = 'encoder2'\r\n",
    "encoder2.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# create model to learn it all\r\n",
    "input1 = Input(shape=image_dim)\r\n",
    "input2 = Input(shape=image_dim)\r\n",
    "enc1_out = encoder1(input1)\r\n",
    "enc2_out = encoder2(input2)\r\n",
    "model_c = Concatenate()([enc1_out,enc2_out])\r\n",
    "model_c = Dense(1000,activation='relu')(model_c)\r\n",
    "\r\n",
    "model_b1 = Dense(200,activation='relu')(model_c)\r\n",
    "model_b2 = Dense(200,activation='relu')(model_c)\r\n",
    "\r\n",
    "#model_b1 = Dense(100,activation='relu')(model_b1)\r\n",
    "#model_b2 = Dense(100,activation='relu')(model_b2)\r\n",
    "\r\n",
    "model_b3 = Dense(200,activation='relu')(model_c)\r\n",
    "model_b4 = Dense(200,activation='relu')(model_c)\r\n",
    "\r\n",
    "#model_b3 = Dense(100,activation='relu')(model_b3)\r\n",
    "#model_b4 = Dense(100,activation='relu')(model_b4)\r\n",
    "\r\n",
    "model_b5 = Dense(200,activation='relu')(model_c)\r\n",
    "#model_b5 = Dense(100,activation='relu')(model_b5)\r\n",
    "\r\n",
    "\r\n",
    "units_add =  Dense(10,activation='softmax',name ='units_add')(model_b1)\r\n",
    "tens_add = Dense(1,activation='sigmoid',name ='tens_add')(model_b2)\r\n",
    "\r\n",
    "units_mult =  Dense(10,activation='softmax',name ='units_mult')(model_b3)\r\n",
    "tens_mult = Dense(9,activation='softmax',name ='tens_mult')(model_b4)\r\n",
    "\r\n",
    "comp =  Dense(1,activation='sigmoid',name ='comp')(model_b5)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "model_complete = Model(inputs=[input1,input2],outputs=[units_add,tens_add,units_mult,tens_mult,comp])\r\n",
    "\r\n",
    "model_complete.compile(optimizer='nadam', loss = ['categorical_crossentropy','binary_crossentropy','categorical_crossentropy','categorical_crossentropy','binary_crossentropy'], metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# generate a dataset for additions\r\n",
    "train_size = 200000\r\n",
    "random_labels1 = np.random.randint(0,25000,train_size)\r\n",
    "random_labels2 = np.random.randint(0,25000,train_size)\r\n",
    "\r\n",
    "x_train_1 = x_train[random_labels1]\r\n",
    "x_train_2 = x_train[random_labels2]\r\n",
    "\r\n",
    "y_train_1 = y_train[random_labels1]\r\n",
    "y_train_2 = y_train[random_labels2]\r\n",
    "\r\n",
    "y_add = y_train_1 + y_train_2\r\n",
    "y_add_tens = y_add //10 \r\n",
    "y_add_units = y_add %10 \r\n",
    "y_add_units_cat = to_categorical(y_add_units)\r\n",
    "\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "test_size = 5000\r\n",
    "random_labels1 = np.random.randint(0,10000,test_size)\r\n",
    "random_labels2 = np.random.randint(0,10000,test_size)\r\n",
    "\r\n",
    "x_test_1 = x_test[random_labels1]\r\n",
    "x_test_2 = x_test[random_labels2]\r\n",
    "\r\n",
    "y_test_1 = y_test[random_labels1]\r\n",
    "y_test_2 = y_test[random_labels2]\r\n",
    "\r\n",
    "y_test_add = y_test_1 + y_test_2\r\n",
    "y_test_add_tens = y_test_add //10 \r\n",
    "y_test_add_units = y_test_add %10 \r\n",
    "y_test_add_units_cat = to_categorical(y_test_add_units)\r\n",
    "\r\n",
    "# generate a dataset for multiplication\r\n",
    "\r\n",
    "y_mult = y_train_1 * y_train_2\r\n",
    "y_mult_tens = y_mult //10 \r\n",
    "y_mult_units = y_mult %10 \r\n",
    "y_mult_units_cat = to_categorical(y_mult_units)\r\n",
    "y_mult_tens_cat = to_categorical(y_mult_tens)\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "\r\n",
    "y_test_mult = y_test_1 * y_test_2\r\n",
    "y_test_mult_tens = y_test_mult //10 \r\n",
    "y_test_mult_units = y_test_mult %10 \r\n",
    "y_test_mult_units_cat = to_categorical(y_test_mult_units)\r\n",
    "y_test_mult_tens_cat = to_categorical(y_test_mult_tens)\r\n",
    "\r\n",
    "# generate a dataset for comparison\r\n",
    "y_comp = y_train_1 > y_train_2\r\n",
    "\r\n",
    "# the same with x_test\r\n",
    "y_test_comp = y_test_1 > y_test_2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "history = model_complete.fit([x_train_1,x_train_2],[y_add_units_cat,y_add_tens,y_mult_units_cat,y_mult_tens_cat,y_comp], batch_size=100,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es,es,es,es,es,es])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "1600/1600 - 45s - loss: 2.5787 - units_add_loss: 0.9021 - tens_add_loss: 0.2324 - units_mult_loss: 0.6609 - tens_mult_loss: 0.5536 - comp_loss: 0.2297 - units_add_acc: 0.7070 - tens_add_acc: 0.9001 - units_mult_acc: 0.7769 - tens_mult_acc: 0.8067 - comp_acc: 0.9022 - val_loss: 1.2447 - val_units_add_loss: 0.4144 - val_tens_add_loss: 0.1246 - val_units_mult_loss: 0.3073 - val_tens_mult_loss: 0.2762 - val_comp_loss: 0.1222 - val_units_add_acc: 0.8749 - val_tens_add_acc: 0.9541 - val_units_mult_acc: 0.9050 - val_tens_mult_acc: 0.9100 - val_comp_acc: 0.9538\n",
      "Epoch 2/1000\n",
      "1600/1600 - 44s - loss: 0.9041 - units_add_loss: 0.2942 - tens_add_loss: 0.0919 - units_mult_loss: 0.2271 - tens_mult_loss: 0.1986 - comp_loss: 0.0923 - units_add_acc: 0.9120 - tens_add_acc: 0.9666 - units_mult_acc: 0.9297 - tens_mult_acc: 0.9361 - comp_acc: 0.9663 - val_loss: 0.7266 - val_units_add_loss: 0.2383 - val_tens_add_loss: 0.0701 - val_units_mult_loss: 0.1812 - val_tens_mult_loss: 0.1622 - val_comp_loss: 0.0748 - val_units_add_acc: 0.9290 - val_tens_add_acc: 0.9759 - val_units_mult_acc: 0.9438 - val_tens_mult_acc: 0.9467 - val_comp_acc: 0.9720\n",
      "Epoch 3/1000\n",
      "1600/1600 - 44s - loss: 0.5536 - units_add_loss: 0.1768 - tens_add_loss: 0.0582 - units_mult_loss: 0.1374 - tens_mult_loss: 0.1225 - comp_loss: 0.0587 - units_add_acc: 0.9465 - tens_add_acc: 0.9788 - units_mult_acc: 0.9572 - tens_mult_acc: 0.9609 - comp_acc: 0.9790 - val_loss: 0.5818 - val_units_add_loss: 0.1833 - val_tens_add_loss: 0.0667 - val_units_mult_loss: 0.1373 - val_tens_mult_loss: 0.1316 - val_comp_loss: 0.0629 - val_units_add_acc: 0.9420 - val_tens_add_acc: 0.9754 - val_units_mult_acc: 0.9558 - val_tens_mult_acc: 0.9552 - val_comp_acc: 0.9768\n",
      "Epoch 4/1000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = model_complete.evaluate([x_test_1,x_test_2],[y_test_add_units_cat,y_test_add_tens,y_test_mult_units_cat,y_test_mult_tens_cat,y_test_comp], batch_size=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_label_1 = np.random.randint(0,9999)\r\n",
    "random_label_2 = np.random.randint(0,9999)\r\n",
    "\r\n",
    "img_sample1 = x_test[random_label_1,:,:].reshape((1,28,28,1))\r\n",
    "img_sample2 = x_test[random_label_2,:,:].reshape((1,28,28,1))\r\n",
    "\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.imshow(img_sample1.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.imshow(img_sample2.reshape(28,28), cmap='gray');\r\n",
    "\r\n",
    "prediction = model_complete.predict([img_sample1,img_sample2])\r\n",
    "unit_add = prediction[0]\r\n",
    "ten_add = prediction[1]\r\n",
    "unit_mult = prediction[2]\r\n",
    "ten_mult = prediction[3]\r\n",
    "\r\n",
    "\r\n",
    "sum_images = np.argmax(unit_add)+10*np.round(ten_add)\r\n",
    "print('sum =',sum_images)\r\n",
    "\r\n",
    "\r\n",
    "mult_images = np.argmax(unit_mult)+10*np.argmax(ten_mult)\r\n",
    "print('multiplication result =',mult_images)\r\n",
    "\r\n",
    "print('comparison result =',np.round(prediction[4]),'1 if the number on the left is greater, 0 elsewhere')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}